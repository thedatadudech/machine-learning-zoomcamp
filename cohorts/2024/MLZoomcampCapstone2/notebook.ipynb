{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Skin Cancer Detection System - Model Development and Analysis\n",
    "\n",
    "This notebook contains the complete process of developing a skin cancer detection system using deep learning, including:\n",
    "- Data loading and preprocessing\n",
    "- Exploratory Data Analysis (EDA)\n",
    "- Model development and training\n",
    "- Performance evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Import required libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from PIL import Image\n",
    "import os\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "import tensorflow as tf\n",
    "\n",
    "# Set random seeds for reproducibility\n",
    "np.random.seed(42)\n",
    "tf.random.set_seed(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Data Loading and Initial Exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Load metadata\n",
    "df = pd.read_csv('data/HAM10000_metadata.csv')\n",
    "print(\"Dataset shape:\", df.shape)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Display basic statistics of the dataset\n",
    "print(\"\\nClass distribution:\")\n",
    "print(df.dx.value_counts())\n",
    "\n",
    "# Visualize class distribution\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.countplot(data=df, x='dx')\n",
    "plt.xticks(rotation=45)\n",
    "plt.title('Distribution of Skin Lesion Types')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Image Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "def analyze_image_properties(data_dir, sample_size=100):\n",
    "    \"\"\"Analyze properties of images in the dataset\"\"\"\n",
    "    image_files = np.random.choice(os.listdir(data_dir), sample_size)\n",
    "    widths, heights = [], []\n",
    "    \n",
    "    for img_file in image_files:\n",
    "        img = Image.open(os.path.join(data_dir, img_file))\n",
    "        widths.append(img.size[0])\n",
    "        heights.append(img.size[1])\n",
    "    \n",
    "    return widths, heights\n",
    "\n",
    "widths, heights = analyze_image_properties('data/images')\n",
    "\n",
    "plt.figure(figsize=(12, 4))\n",
    "plt.subplot(121)\n",
    "plt.hist(widths)\n",
    "plt.title('Image Widths Distribution')\n",
    "plt.subplot(122)\n",
    "plt.hist(heights)\n",
    "plt.title('Image Heights Distribution')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Data Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "from src.data_loader import DataLoader\n",
    "\n",
    "# Initialize data loader\n",
    "data_loader = DataLoader(\n",
    "    data_dir='data/images',\n",
    "    metadata_path='data/HAM10000_metadata.csv'\n",
    ")\n",
    "\n",
    "# Load and split data\n",
    "(X_train, y_train), (X_val, y_val), (X_test, y_test) = data_loader.load_data()\n",
    "\n",
    "print(\"Training set shape:\", X_train.shape)\n",
    "print(\"Validation set shape:\", X_val.shape)\n",
    "print(\"Test set shape:\", X_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Model Development and Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "from src.model import create_efficient_net, create_resnet, create_custom_cnn\n",
    "from src.preprocessing import create_data_augmentation\n",
    "\n",
    "# Model configurations\n",
    "INPUT_SHAPE = (224, 224, 3)\n",
    "NUM_CLASSES = 7\n",
    "BATCH_SIZE = 32\n",
    "EPOCHS = 50\n",
    "\n",
    "# Create models\n",
    "models = {\n",
    "    'EfficientNet': create_efficient_net(INPUT_SHAPE, NUM_CLASSES),\n",
    "    'ResNet': create_resnet(INPUT_SHAPE, NUM_CLASSES),\n",
    "    'CustomCNN': create_custom_cnn(INPUT_SHAPE, NUM_CLASSES)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Training configuration\n",
    "data_augmentation = create_data_augmentation()\n",
    "\n",
    "callbacks = [\n",
    "    tf.keras.callbacks.EarlyStopping(\n",
    "        monitor='val_loss',\n",
    "        patience=5,\n",
    "        restore_best_weights=True\n",
    "    ),\n",
    "    tf.keras.callbacks.ReduceLROnPlateau(\n",
    "        monitor='val_loss',\n",
    "        factor=0.2,\n",
    "        patience=3\n",
    "    )\n",
    "]\n",
    "\n",
    "# Dictionary to store training histories\n",
    "histories = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Train and evaluate each model\n",
    "for name, model in models.items():\n",
    "    print(f\"\\nTraining {name}...\")\n",
    "    \n",
    "    model.compile(\n",
    "        optimizer=tf.keras.optimizers.Adam(1e-4),\n",
    "        loss='categorical_crossentropy',\n",
    "        metrics=['accuracy']\n",
    "    )\n",
    "    \n",
    "    history = model.fit(\n",
    "        data_augmentation(X_train),\n",
    "        y_train,\n",
    "        batch_size=BATCH_SIZE,\n",
    "        epochs=EPOCHS,\n",
    "        validation_data=(X_val, y_val),\n",
    "        callbacks=callbacks\n",
    "    )\n",
    "    \n",
    "    histories[name] = history.history"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Model Comparison and Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Plot training histories\n",
    "plt.figure(figsize=(15, 5))\n",
    "\n",
    "plt.subplot(121)\n",
    "for name, history in histories.items():\n",
    "    plt.plot(history['accuracy'], label=f'{name} (train)')\n",
    "    plt.plot(history['val_accuracy'], label=f'{name} (val)')\n",
    "plt.title('Model Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "\n",
    "plt.subplot(122)\n",
    "for name, history in histories.items():\n",
    "    plt.plot(history['loss'], label=f'{name} (train)')\n",
    "    plt.plot(history['val_loss'], label=f'{name} (val)')\n",
    "plt.title('Model Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Evaluate models on test set\n",
    "test_results = {}\n",
    "for name, model in models.items():\n",
    "    test_loss, test_acc = model.evaluate(X_test, y_test, verbose=0)\n",
    "    test_results[name] = {\n",
    "        'accuracy': test_acc,\n",
    "        'loss': test_loss\n",
    "    }\n",
    "    print(f\"\\n{name} Test Accuracy: {test_acc:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Save Best Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Find and save the best model\n",
    "best_model_name = max(test_results, key=lambda k: test_results[k]['accuracy'])\n",
    "best_model = models[best_model_name]\n",
    "\n",
    "os.makedirs('models', exist_ok=True)\n",
    "best_model.save('models/best_model.h5')\n",
    "print(f\"Best model ({best_model_name}) saved with test accuracy: {test_results[best_model_name]['accuracy']:.4f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
