{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "T4",
      "authorship_tag": "ABX9TyNlR33jG9OBTWbeqBqVTqe4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/thedatadudech/machine-learning-zoomcamp/blob/homework09/homework09.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!wget https://github.com/alexeygrigorev/large-datasets/releases/download/hairstyle/model_2024_hairstyle.keras"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_WIVwosaiZkF",
        "outputId": "bbcd11f5-f9c3-44ea-8243-c001a34e9d65"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2024-12-09 13:09:08--  https://github.com/alexeygrigorev/large-datasets/releases/download/hairstyle/model_2024_hairstyle.keras\n",
            "Resolving github.com (github.com)... 20.205.243.166\n",
            "Connecting to github.com (github.com)|20.205.243.166|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://objects.githubusercontent.com/github-production-release-asset-2e65be/426348925/df5735c1-9082-4b67-968e-866f268793f8?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=releaseassetproduction%2F20241209%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20241209T130908Z&X-Amz-Expires=300&X-Amz-Signature=dc02bf4a9ec3f14a3b13889355b57b110236188ffaf68070cae48b82374b6201&X-Amz-SignedHeaders=host&response-content-disposition=attachment%3B%20filename%3Dmodel_2024_hairstyle.keras&response-content-type=application%2Foctet-stream [following]\n",
            "--2024-12-09 13:09:09--  https://objects.githubusercontent.com/github-production-release-asset-2e65be/426348925/df5735c1-9082-4b67-968e-866f268793f8?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=releaseassetproduction%2F20241209%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20241209T130908Z&X-Amz-Expires=300&X-Amz-Signature=dc02bf4a9ec3f14a3b13889355b57b110236188ffaf68070cae48b82374b6201&X-Amz-SignedHeaders=host&response-content-disposition=attachment%3B%20filename%3Dmodel_2024_hairstyle.keras&response-content-type=application%2Foctet-stream\n",
            "Resolving objects.githubusercontent.com (objects.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to objects.githubusercontent.com (objects.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 160610502 (153M) [application/octet-stream]\n",
            "Saving to: ‘model_2024_hairstyle.keras’\n",
            "\n",
            "model_2024_hairstyl 100%[===================>] 153.17M  36.3MB/s    in 4.2s    \n",
            "\n",
            "2024-12-09 13:09:14 (36.3 MB/s) - ‘model_2024_hairstyle.keras’ saved [160610502/160610502]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n96M-IKhhqv7",
        "outputId": "544ea908-6af2-48c7-fcee-ef4cfe7b0bdc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saved artifact at '/tmp/tmprdfnahqe'. The following endpoints are available:\n",
            "\n",
            "* Endpoint 'serve'\n",
            "  args_0 (POSITIONAL_ONLY): TensorSpec(shape=(None, 200, 200, 3), dtype=tf.float32, name='input_layer')\n",
            "Output Type:\n",
            "  TensorSpec(shape=(None, 1), dtype=tf.float32, name=None)\n",
            "Captures:\n",
            "  134365580079376: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  134362345681344: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  134362331599040: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  134362331649072: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  134362331599392: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  134362331652944: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "Size of the converted model: 76.58 MB\n"
          ]
        }
      ],
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "# Load the Keras model\n",
        "model = tf.keras.models.load_model('model_2024_hairstyle.keras')\n",
        "\n",
        "# Convert the model to TF-Lite\n",
        "converter = tf.lite.TFLiteConverter.from_keras_model(model)\n",
        "tflite_model = converter.convert()\n",
        "\n",
        "# Save the TF-Lite model to disk\n",
        "with open('model_2024_hairstyle.tflite', 'wb') as f:\n",
        "    f.write(tflite_model)\n",
        "\n",
        "# Print the size of the converted model\n",
        "import os\n",
        "print(f\"Size of the converted model: {os.path.getsize('model_2024_hairstyle.tflite') / 1024 / 1024:.2f} MB\")\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the TFLite model and allocate tensors.\n",
        "interpreter = tf.lite.Interpreter(model_path=\"model_2024_hairstyle.tflite\")\n",
        "interpreter.allocate_tensors()\n",
        "\n",
        "# Get input and output tensors.\n",
        "input_details = interpreter.get_input_details()\n",
        "output_details = interpreter.get_output_details()\n",
        "\n",
        "# Get indices of the input and output tensors\n",
        "print(\"Input index:\", input_details[0]['index'])\n",
        "print(\"Output index:\", output_details[0]['index'])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FCFJoT_aikw5",
        "outputId": "740e103f-aaa7-42ce-ff89-85fc0a6e800a"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input index: 0\n",
            "Output index: 13\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from io import BytesIO\n",
        "from urllib import request\n",
        "\n",
        "from PIL import Image\n",
        "\n",
        "def download_image(url):\n",
        "    with request.urlopen(url) as resp:\n",
        "        buffer = resp.read()\n",
        "    stream = BytesIO(buffer)\n",
        "    img = Image.open(stream)\n",
        "    return img\n",
        "\n",
        "\n",
        "def prepare_image(img, target_size):\n",
        "    if img.mode != 'RGB':\n",
        "        img = img.convert('RGB')\n",
        "    img = img.resize(target_size, Image.NEAREST)\n",
        "    return img"
      ],
      "metadata": {
        "id": "lxLpSGw3jM0g"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Question 3\n"
      ],
      "metadata": {
        "id": "K9GZUZ7lltLC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "image_url = \"https://habrastorage.org/webt/yf/_d/ok/yf_dokzqy3vcritme8ggnzqlvwa.jpeg\"\n",
        "\n",
        "img = download_image(image_url)\n",
        "img = prepare_image(img, target_size=(200, 200))\n",
        "\n",
        "\n",
        "import numpy as np\n",
        "\n",
        "# Assuming 'img' is loaded and resized to the target size\n",
        "img_array = np.array(img, dtype=np.float32) / 255.0  # Scale pixel values and ensure dtype is float32\n",
        "print(\"First pixel, R channel value:\", img_array[0,0,0])\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-XWA7_rsjQLp",
        "outputId": "0c0c1779-986a-448a-ab72-173b2a99b306"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "First pixel, R channel value: 0.23921569\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Question 4"
      ],
      "metadata": {
        "id": "HY4o3s5Dlvy3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Set the input tensor\n",
        "interpreter.set_tensor(input_details[0]['index'], np.expand_dims(img_array, axis=0))\n",
        "\n",
        "# Run inference\n",
        "interpreter.invoke()\n",
        "\n",
        "# Get the output\n",
        "output_data = interpreter.get_tensor(output_details[0]['index'])\n",
        "print(\"Model output:\", output_data)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DzhbnNxMj39x",
        "outputId": "83e3a975-785a-498c-ce39-7f730a0e811d"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model output: [[0.8937741]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Question 5"
      ],
      "metadata": {
        "id": "zy6LoeHB9RK7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"The size of the image is  782MB\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sl1pR-ASsvRw",
        "outputId": "90b4136d-2539-46d0-fffe-9adbd3eebcd6"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The size of the image is  782MB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Question 6"
      ],
      "metadata": {
        "id": "X0Sy99W-9TQ5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"The output of the model is [0.42985352873802185]\")\n",
        "#Check folder cohort/2024/09-Serverless , build and run docker image"
      ],
      "metadata": {
        "id": "KOymTRoks1js"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}